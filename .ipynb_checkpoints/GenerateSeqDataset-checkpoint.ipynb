{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from utils.shapefiles import sampleShapefileLocations\n",
    "from analysis.peaksdata import filterPeaksHaversineDist\n",
    "from utils.divtree_gen import *\n",
    "from utils.seqdata_gen import *\n",
    "from utils.seq2demodst import *\n",
    "# process each region (note: it takes a long time!)\n",
    "regionShapesDir = 'data/regionShapes'\n",
    "regionPeaksDir = 'data/regionPeaks'\n",
    "regionSeqsDir = 'data/regionSeqs'\n",
    "regionTreeSeqsDir = 'data/regionTreeSeqs'\n",
    "diskRadius = 30\n",
    "\n",
    "regionShapes = ['andes_peru.shp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For RNN, sequence representation of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andes_peru.shp :  213 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [31:37,  8.91s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'allSeqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-35afaf36babe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mallTrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqOfTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregionTreeSeqsDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.shp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mseqTree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallSeqs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'allSeqs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for region in regionShapes:\n",
    "    st = time.time()\n",
    "    # sample stats locations inside polygon, separated at least 1/2 radius distance\n",
    "    sampleLocations = sampleShapefileLocations(os.path.join(regionShapesDir, region), diskRadius)\n",
    "    print(region, \": \", len(sampleLocations), \"samples\")\n",
    "    # region peaks DB\n",
    "    df = pd.read_csv(os.path.join(regionPeaksDir, region.replace('.shp', '.csv')))\n",
    "\n",
    "    allTrees = []\n",
    "    # compute sequences\n",
    "    for di,diskCenter in tqdm(enumerate(sampleLocations)):\n",
    "        # filter peaks in disk using haversine distance\n",
    "        peaks = filterPeaksHaversineDist(df, diskCenter, diskRadius)\n",
    "        # skip if not enough peaks\n",
    "        if peaks.shape[0] < 20:\n",
    "            continue\n",
    "        # build the divide tree\n",
    "        rootNode = genDivideTree(peaks)\n",
    "        seqOfTree = genFullSeq(rootNode, isDFS=True)\n",
    "        allTrees.append(seqOfTree)\n",
    "    fout = open(os.path.join(regionTreeSeqsDir, region.replace('.shp', '.txt')), 'w') \n",
    "    for seqTree in allTrees:\n",
    "        fout.write(\",\".join( [\";\".join([str(i) for i in v] ) for v in s]))\n",
    "        fout.write('\\n')\n",
    "    fout.close()\n",
    "\n",
    "    print('%s: %3d samples, %3d sequences, %d s'%(region, len(sampleLocations), len(allSeqs), time.time() - st)) \n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for region in regionShapes:\n",
    "    st = time.time()\n",
    "    # sample stats locations inside polygon, separated at least 1/2 radius distance\n",
    "    sampleLocations = sampleShapefileLocations(os.path.join(regionShapesDir, region), diskRadius)\n",
    "    print(region, \": \", len(sampleLocations), \"samples\")\n",
    "    # region peaks DB\n",
    "    df = pd.read_csv(os.path.join(regionPeaksDir, region.replace('.shp', '.csv')))\n",
    "\n",
    "    allSeqs = []\n",
    "    # compute sequences\n",
    "    for di,diskCenter in enumerate(sampleLocations):\n",
    "        # filter peaks in disk using haversine distance\n",
    "        peaks = filterPeaksHaversineDist(df, diskCenter, diskRadius)\n",
    "        # skip if not enough peaks\n",
    "        if peaks.shape[0] < 20:\n",
    "            continue\n",
    "        paths = genSeq(peaks)\n",
    "        seqs = [p for p in paths if len(p) > 10]\n",
    "        allSeqs += seqs\n",
    "        # for debug, draw Seqs tree\n",
    "        # drawSeq(peaks, seqs)\n",
    "        print('%s: %3d/%3d samples '%(region, di+1, len(sampleLocations)), end='\\r' if di+1 < len(sampleLocations) else '\\n')\n",
    "    fout = open(os.path.join(regionSeqsDir, region.replace('.shp', '.txt')), 'w') \n",
    "    for s in allSeqs:\n",
    "        fout.write(\" \".join([str(v) for v in s]))\n",
    "        fout.write('\\n')\n",
    "    fout.close()\n",
    "\n",
    "    print('%s: %3d samples, %3d sequences, %d s'%(region, len(sampleLocations), len(allSeqs), time.time() - st)) \n",
    "\n",
    "print('done!')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
