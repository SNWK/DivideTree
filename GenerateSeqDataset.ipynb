{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "from utils.shapefiles import sampleShapefileLocations\n",
    "from analysis.peaksdata import filterPeaksHaversineDist\n",
    "from utils.divtree_gen import *\n",
    "from utils.seqdata_gen import *\n",
    "from utils.seq2demodst import *\n",
    "# process each region (note: it takes a long time!)\n",
    "regionShapesDir = 'data/regionShapes'\n",
    "regionPeaksDir = 'data/regionPeaks'\n",
    "regionSeqsDir = 'data/regionSeqs'\n",
    "regionTreeSeqsDir = 'data/regionTreeSeqs'\n",
    "\n",
    "regionShapes = ['andes_peru.shp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DGMG, sequence representation of node addation and connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "0it [00:00, ?it/s]andes_peru.shp :  2335 samples\n2335it [07:19,  5.32it/s]\n2304\nandes_peru.shp: 2335 samples, 2304 sequences, 441 s\ndone!\n"
    }
   ],
   "source": [
    "\n",
    "diskRadius = 10\n",
    "for region in regionShapes:\n",
    "    st = time.time()\n",
    "    # sample stats locations inside polygon, separated at least 1/2 radius distance\n",
    "    sampleLocations = sampleShapefileLocations(os.path.join(regionShapesDir, region), diskRadius)\n",
    "    print(region, \": \", len(sampleLocations), \"samples\")\n",
    "    # region peaks DB\n",
    "    df = pd.read_csv(os.path.join(regionPeaksDir, region.replace('.shp', '.csv')))\n",
    "\n",
    "    good = 0\n",
    "\n",
    "    allTrees = []\n",
    "    # compute sequences\n",
    "    for di,diskCenter in tqdm(enumerate(sampleLocations)):\n",
    "        # filter peaks in disk using haversine distance\n",
    "        peaks = filterPeaksHaversineDist(df, diskCenter, diskRadius)\n",
    "        # skip if not enough peaks\n",
    "        if peaks.shape[0] < 10:\n",
    "            continue\n",
    "        good += 1\n",
    "        # build the divide trees\n",
    "        rootidx = peaks['elevation in feet'].idxmax()\n",
    "        peaks['longitude'] -= peaks['longitude'].loc[rootidx]\n",
    "        peaks['latitude'] -= peaks['latitude'].loc[rootidx]\n",
    "        \n",
    "        rootNode = genDivideTree(peaks)\n",
    "        seqOfTree = genFullSeqDGMG(rootNode, isDFS=False)\n",
    "        allTrees.append(seqOfTree)\n",
    "    \n",
    "    print(good)\n",
    "    with open(os.path.join(regionTreeSeqsDir, region.replace('.shp', 'DGMGL.txt')), 'wb') as f:\n",
    "        pickle.dump(allTrees, f)\n",
    "\n",
    "    print('%s: %3d samples, %3d sequences, %d s'%(region, len(sampleLocations), len(allTrees), time.time() - st)) \n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(regionTreeSeqsDir, region.replace('.shp', 'DGMGL.txt')), 'wb') as f:\n",
    "    pickle.dump(allTrees, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For RNN, sequence representation of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "0it [00:00, ?it/s]andes_peru.shp :  526 samples\n526\n526it [20:48,  2.37s/it]\nandes_peru.shp: 526 samples, 526 sequences, 1249 s\ndone!\n"
    }
   ],
   "source": [
    "\n",
    "diskRadius = 20\n",
    "for region in regionShapes:\n",
    "    st = time.time()\n",
    "    # sample stats locations inside polygon, separated at least 1/2 radius distance\n",
    "    sampleLocations = sampleShapefileLocations(os.path.join(regionShapesDir, region), diskRadius)\n",
    "    print(region, \": \", len(sampleLocations), \"samples\")\n",
    "    # region peaks DB\n",
    "    df = pd.read_csv(os.path.join(regionPeaksDir, region.replace('.shp', '.csv')))\n",
    "    print(len(sampleLocations))\n",
    "    allTrees = []\n",
    "    # compute sequences\n",
    "    for di,diskCenter in tqdm(enumerate(sampleLocations)):\n",
    "        # filter peaks in disk using haversine distance\n",
    "        peaks = filterPeaksHaversineDist(df, diskCenter, diskRadius)\n",
    "        # skip if not enough peaks\n",
    "        if peaks.shape[0] < 10:\n",
    "            continue\n",
    "        # build the divide tree\n",
    "        rootNode = genDivideTree(peaks)\n",
    "        seqOfTree = genFullSeqRNN(rootNode, isDFS=True)\n",
    "        allTrees.append(seqOfTree)\n",
    "    fout = open(os.path.join(regionTreeSeqsDir, region.replace('.shp', 'little.txt')), 'w') \n",
    "    for seqTree in allTrees:\n",
    "        fout.write(\",\".join( [\";\".join([str(i) for i in v] ) for v in seqTree]))\n",
    "        fout.write('\\n')\n",
    "    fout.close()\n",
    "\n",
    "    print('%s: %3d samples, %3d sequences, %d s'%(region, len(sampleLocations), len(allTrees), time.time() - st)) \n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test, Find max-min for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regionShapes:\n",
    "    file_in = open(os.path.join(regionTreeSeqsDir, region.replace('.shp', '.txt')), 'r')\n",
    "    allpoints = []\n",
    "    for line in file_in.readlines():\n",
    "        for s in line.split(','):\n",
    "            allpoints.append([float(c) for c in s.split(';')])\n",
    "    allpoints = np.array(allpoints)\n",
    "    datamax = allpoints.max(axis=0)\n",
    "    datamin = allpoints.min(axis=0)\n",
    "    datamean = allpoints.mean(axis=0)\n",
    "    datastd = allpoints.std(axis=0)\n",
    "    print(datamax)\n",
    "    print(datamin)\n",
    "    print(datamean)\n",
    "    print(datastd)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for region in regionShapes:\n",
    "    st = time.time()\n",
    "    # sample stats locations inside polygon, separated at least 1/2 radius distance\n",
    "    sampleLocations = sampleShapefileLocations(os.path.join(regionShapesDir, region), diskRadius)\n",
    "    print(region, \": \", len(sampleLocations), \"samples\")\n",
    "    # region peaks DB\n",
    "    df = pd.read_csv(os.path.join(regionPeaksDir, region.replace('.shp', '.csv')))\n",
    "\n",
    "    allSeqs = []\n",
    "    # compute sequences\n",
    "    for di,diskCenter in enumerate(sampleLocations):\n",
    "        # filter peaks in disk using haversine distance\n",
    "        peaks = filterPeaksHaversineDist(df, diskCenter, diskRadius)\n",
    "        # skip if not enough peaks\n",
    "        if peaks.shape[0] < 20:\n",
    "            continue\n",
    "        paths = genSeq(peaks)\n",
    "        seqs = [p for p in paths if len(p) > 10]\n",
    "        allSeqs += seqs\n",
    "        # for debug, draw Seqs tree\n",
    "        # drawSeq(peaks, seqs)\n",
    "        print('%s: %3d/%3d samples '%(region, di+1, len(sampleLocations)), end='\\r' if di+1 < len(sampleLocations) else '\\n')\n",
    "    fout = open(os.path.join(regionSeqsDir, region.replace('.shp', '.txt')), 'w') \n",
    "    for s in allSeqs:\n",
    "        fout.write(\" \".join([str(v) for v in s]))\n",
    "        fout.write('\\n')\n",
    "    fout.close()\n",
    "\n",
    "    print('%s: %3d samples, %3d sequences, %d s'%(region, len(sampleLocations), len(allSeqs), time.time() - st)) \n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python pytorch 0.4.0",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}