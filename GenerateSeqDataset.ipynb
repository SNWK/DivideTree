{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from utils.shapefiles import sampleShapefileLocations\n",
    "from analysis.peaksdata import filterPeaksHaversineDist\n",
    "from utils.divtree_gen import *\n",
    "from utils.seqdata_gen import *\n",
    "from utils.seq2demodst import *\n",
    "# process each region (note: it takes a long time!)\n",
    "regionShapesDir = 'data/regionShapes'\n",
    "regionPeaksDir = 'data/regionPeaks'\n",
    "regionSeqsDir = 'data/regionSeqs'\n",
    "regionTreeSeqsDir = 'data/regionTreeSeqs'\n",
    "\n",
    "regionShapes = ['andes_peru.shp']"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For RNN, sequence representation of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "0it [00:00, ?it/s]andes_peru.shp :  522 samples\n522\n522it [19:57,  2.29s/it]\nandes_peru.shp: 522 samples, 522 sequences, 1198 s\ndone!\n"
    }
   ],
   "source": [
    "\n",
    "diskRadius = 20\n",
    "for region in regionShapes:\n",
    "    st = time.time()\n",
    "    # sample stats locations inside polygon, separated at least 1/2 radius distance\n",
    "    sampleLocations = sampleShapefileLocations(os.path.join(regionShapesDir, region), diskRadius)\n",
    "    print(region, \": \", len(sampleLocations), \"samples\")\n",
    "    # region peaks DB\n",
    "    df = pd.read_csv(os.path.join(regionPeaksDir, region.replace('.shp', '.csv')))\n",
    "    print(len(sampleLocations))\n",
    "    allTrees = []\n",
    "    # compute sequences\n",
    "    for di,diskCenter in tqdm(enumerate(sampleLocations)):\n",
    "        # filter peaks in disk using haversine distance\n",
    "        peaks = filterPeaksHaversineDist(df, diskCenter, diskRadius)\n",
    "        # skip if not enough peaks\n",
    "        if peaks.shape[0] < 10:\n",
    "            continue\n",
    "        # build the divide tree\n",
    "        rootNode = genDivideTree(peaks)\n",
    "        seqOfTree = genFullSeq(rootNode, isDFS=True)\n",
    "        allTrees.append(seqOfTree)\n",
    "    fout = open(os.path.join(regionTreeSeqsDir, region.replace('.shp', 'little.txt')), 'w') \n",
    "    for seqTree in allTrees:\n",
    "        fout.write(\",\".join( [\";\".join([str(i) for i in v] ) for v in seqTree]))\n",
    "        fout.write('\\n')\n",
    "    fout.close()\n",
    "\n",
    "    print('%s: %3d samples, %3d sequences, %d s'%(region, len(sampleLocations), len(allTrees), time.time() - st)) \n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test, Find max-min for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regionShapes:\n",
    "    file_in = open(os.path.join(regionTreeSeqsDir, region.replace('.shp', '.txt')), 'r')\n",
    "    allpoints = []\n",
    "    for line in file_in.readlines():\n",
    "        for s in line.split(','):\n",
    "            allpoints.append([float(c) for c in s.split(';')])\n",
    "    allpoints = np.array(allpoints)\n",
    "    datamax = allpoints.max(axis=0)\n",
    "    datamin = allpoints.min(axis=0)\n",
    "    datamean = allpoints.mean(axis=0)\n",
    "    datastd = allpoints.std(axis=0)\n",
    "    print(datamax)\n",
    "    print(datamin)\n",
    "    print(datamean)\n",
    "    print(datastd)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for region in regionShapes:\n",
    "    st = time.time()\n",
    "    # sample stats locations inside polygon, separated at least 1/2 radius distance\n",
    "    sampleLocations = sampleShapefileLocations(os.path.join(regionShapesDir, region), diskRadius)\n",
    "    print(region, \": \", len(sampleLocations), \"samples\")\n",
    "    # region peaks DB\n",
    "    df = pd.read_csv(os.path.join(regionPeaksDir, region.replace('.shp', '.csv')))\n",
    "\n",
    "    allSeqs = []\n",
    "    # compute sequences\n",
    "    for di,diskCenter in enumerate(sampleLocations):\n",
    "        # filter peaks in disk using haversine distance\n",
    "        peaks = filterPeaksHaversineDist(df, diskCenter, diskRadius)\n",
    "        # skip if not enough peaks\n",
    "        if peaks.shape[0] < 20:\n",
    "            continue\n",
    "        paths = genSeq(peaks)\n",
    "        seqs = [p for p in paths if len(p) > 10]\n",
    "        allSeqs += seqs\n",
    "        # for debug, draw Seqs tree\n",
    "        # drawSeq(peaks, seqs)\n",
    "        print('%s: %3d/%3d samples '%(region, di+1, len(sampleLocations)), end='\\r' if di+1 < len(sampleLocations) else '\\n')\n",
    "    fout = open(os.path.join(regionSeqsDir, region.replace('.shp', '.txt')), 'w') \n",
    "    for s in allSeqs:\n",
    "        fout.write(\" \".join([str(v) for v in s]))\n",
    "        fout.write('\\n')\n",
    "    fout.close()\n",
    "\n",
    "    print('%s: %3d samples, %3d sequences, %d s'%(region, len(sampleLocations), len(allSeqs), time.time() - st)) \n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python pytorch 0.4.0",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}